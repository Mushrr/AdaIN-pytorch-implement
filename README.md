# AdaIN-pytorch-implement

![cheems](https://github.com/HuangXingjie2002/AdaIN-pytorch-implement/blob/main/image/READEME/d__github_AdaIN_AtentionAETransfer.png)
![lighthouse](https://github.com/HuangXingjie2002/AdaIN-pytorch-implement/blob/main/image/READEME/d__Code_2022_Poetry-Cloud_StyleTransForm_src_AtentionAETransfer_AtentionAETransfer.png)
ä½ éœ€è¦å®‰è£…å¦‚ä¸‹pythonåº“


```python
# pytorch
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
# or
conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch

# opencv
pip install opencv-python
# or
conda install opencv-python

# å…¶ä»–pythonåŸºç¡€åº“
```
*å¦‚æœæƒ³è‡ªå·±å®ç°ä¸€æ¬¡çš„è¯ï¼Œå¯ä»¥çœ‹AdaINImplement.md, æä¾›äº†ä¸€ç§å®ç°æ€è·¯*

#### é£Ÿç”¨æ–¹æ³•

1. é…ç½®æ–‡ä»¶è§£è¯»

```python
device = 'cuda' if torch.cuda.is_available() else 'cpu' # åˆ¤æ–­æ˜¯å¦æœ‰GPU
styleName = 'Monet-Transfer-Model' 
transformParamDir = './preTrainModels/monet.pt' # å‚æ•°æ–‡ä»¶
styleLayers = ['ReLU_1', 'ReLU_2', 'ReLU_3'] # ç‰¹å¾æå–çš„ç»´åº¦, å¯ä»¥è‡ªç”±é€‰æ‹©
styleWeight = 0.3
trainingImageSize = 256 # æ¨èè®¾ç½®å°ä¸€ç‚¹ï¼Œå› ä¸ºè®¡ç®—èµ„æºä¸è¶³
outputImageSize = 1024 # è¾“å‡ºå›¾ç‰‡ç»´åº¦, è§†æƒ…å†µè€Œå®š
outputImageName = './data/test/output.jpg'
lr = 0.0001 # å¦‚æœLOSS ä¸ä¸‹é™çš„è¯ï¼Œéœ€è¦æŠŠå­¦ä¹ ç‡é™ä½
epochs = 1000 # è®­ç»ƒæ¬¡æ•°

styleSrc = './data/ori/monet.jpg'             # é£æ ¼å›¾ç‰‡åœ°å€
contentSrc = './data/ori/lightHouse.jpg'      # å†…å®¹å›¾ç‰‡åœ°å€
```
> æ‰€æœ‰çš„å¯é…ç½®ä¿¡æ¯éƒ½åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜¾ç¤ºï¼Œä¸è®ºæ˜¯æ¨¡å‹çš„æ„å»ºè¿˜æ˜¯å›¾ç‰‡çš„é£æ ¼è¿ç§»éƒ½åœ¨è¿™é‡Œ
> 1. æŒ‡å®šé£æ ¼å›¾ç‰‡çš„åœ°å€`styleSrc`ï¼Œ`epochs`ï¼Œ`lr`ï¼Œ `trainingImageSize`ç”¨äºæ„å»ºæ¨¡å‹
> 2. æŒ‡å®šå†…å®¹å›¾ç‰‡çš„åœ°å€`contentSrc`, é£æ ¼è¿ç§»çš„å‚æ•°`transformParamDir`, ç”¨äºç”Ÿæˆå›¾ç‰‡

2. æ¨¡å‹çš„æ„å»º

åœ¨é…ç½®å¥½`config.py`ä¹‹åï¼Œç›´æ¥è¿è¡Œ`buildTransFormParam.py`æ–‡ä»¶ï¼Œä¼šè‡ªåŠ¨æ„å»ºè¯¥é£æ ¼å›¾ç‰‡çš„é£æ ¼è§£ç å™¨ã€‚
```python
>>> python buildTransFormParam.py
Loading Packages ...
Done
Loading style image ...
Done
Loading content image ...
Done
Loading VGG19 ...
Done
Decoder generate ...
Done
Build AdaINTransfer model ...
Done
Optimizing ...
[0]:    [Loss]: 2.472977876663208       [Content Loss]: 2.286891460418701       [Style Loss]: 0.6202879548072815
[20]:   [Loss]: 2.2495431900024414      [Content Loss]: 2.106981039047241       [Style Loss]: 0.4752069115638733
...

Done
Model has been saved, name: StarryNight-Transfer-Model1000_decoder.pt # æ¨¡å‹ä¿å­˜çš„åç§°
```

3. é£æ ¼å›¾ç‰‡çš„ç”Ÿæˆ

åœ¨å¾—åˆ°æ¨¡å‹åï¼Œå†åœ¨congfig.pyä¸­å®šä¹‰æ¨¡å‹çš„åœ°å€`transformParamDir`, éšåæŒ‡å®šè¾“å‡ºå›¾ç‰‡çš„å¤§å°å’Œå†…å®¹å›¾ç‰‡çš„åœ°å€ï¼Œ
æ³¨æ„æ­¤æ—¶é£æ ¼å›¾ç‰‡åœ°å€ä¸å¯ä»¥æ”¹å˜ï¼Œå¦‚æœæ”¹å˜çš„è¯å°±æ˜¯ä¸åŒé£æ ¼çš„èåˆäº†ã€‚  
è¿è¡Œ`styleImageGenerate.py`  
```python
python styleImageGenerate.py       

Load Vgg ...
Done !
Initialize ...
Done !
Generating ...
Done !
```
å›¾ç‰‡ä¼šè‡ªåŠ¨ä¿å­˜åœ¨ä½ ä¹‹å‰å®šä¹‰çš„ä½ç½®`outputImageName`

*ç”±äºAdaIN - decoder*æ˜¯ä¸€ç§æ•ˆç‡éå¸¸é«˜çš„åŸºç¡€è¿ç§»ç®—æ³•ï¼Œä½ ç”šè‡³å¯ä»¥å®æ—¶è§†é¢‘é£æ ¼è¿ç§»ï¼Œ  
å¦‚æœä½ æ„¿æ„ï¼Œä½ å¯ä»¥è¯•è¯•`VideoFastTransform.py`, ä½“éªŒä¸€æŠŠé£æ ¼æ»¤é•œä¸‹çš„ä½ ï¼ˆæ•ˆæœå¯èƒ½ä¸æ˜¯ç‰¹åˆ«å¥½ï¼Œå—å™ªå£°çš„å½±å“æ¯”è¾ƒå¤§ğŸ¤ªğŸ¤ªğŸ¤ªğŸ¤ªï¼‰

**è®ºæ–‡åœ°å€**
[Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization](https://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Arbitrary_Style_Transfer_ICCV_2017_paper.pdf)
